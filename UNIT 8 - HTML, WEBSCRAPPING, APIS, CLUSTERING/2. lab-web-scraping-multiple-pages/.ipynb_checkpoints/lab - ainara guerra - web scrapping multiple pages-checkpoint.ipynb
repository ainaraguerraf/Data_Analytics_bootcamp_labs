{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19dfc2c9",
   "metadata": {},
   "source": [
    "# <span style=\"color:rgb(255, 0, 255)\"> Lab Web Scrapping multiple pages\n",
    "<span style=\"color:rgb(255, 0, 255)\"> Ainara Guerra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c6cf27",
   "metadata": {},
   "source": [
    "#### <span style=\"color:rgb(255, 0, 255)\"> Instructions of the previous labs\n",
    "Your product will take a song as an input from the user and will output another song (the recommendation). \n",
    "In most cases, the recommended song will have to be similar to the inputted song, but the CTO thinks that if the song is on the top charts at the moment, the user will enjoy more a recommendation of a song that's also popular at the moment.\n",
    "\n",
    "You have find data on the internet about currently popular songs. Billboard maintains a weekly Top 100 of \"hot\" songs here: https://www.billboard.com/charts/hot-100.\n",
    "\n",
    "It's a good place to start! Scrape the current top 100 songs and their respective artists, and put the information into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "da01b54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bc6e124f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song</th>\n",
       "      <th>Artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Last Night</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flowers</td>\n",
       "      <td>Miley Cyrus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fast Car</td>\n",
       "      <td>Luke Combs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Calm Down</td>\n",
       "      <td>Rema &amp; Selena Gomez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>All My Life</td>\n",
       "      <td>Lil Durk Featuring J. Cole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Save Me</td>\n",
       "      <td>Jelly Roll With Lainey Wilson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Yandel 150</td>\n",
       "      <td>Yandel &amp; Feid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Beso</td>\n",
       "      <td>Rosalia &amp; Rauw Alejandro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>I Wrote The Book</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Hummingbird</td>\n",
       "      <td>Metro Boomin &amp; James Blake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Song                         Artist\n",
       "0         Last Night                  Morgan Wallen\n",
       "1            Flowers                    Miley Cyrus\n",
       "2           Fast Car                     Luke Combs\n",
       "3          Calm Down            Rema & Selena Gomez\n",
       "4        All My Life     Lil Durk Featuring J. Cole\n",
       "..               ...                            ...\n",
       "95           Save Me  Jelly Roll With Lainey Wilson\n",
       "96        Yandel 150                  Yandel & Feid\n",
       "97              Beso       Rosalia & Rauw Alejandro\n",
       "98  I Wrote The Book                  Morgan Wallen\n",
       "99       Hummingbird     Metro Boomin & James Blake\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = requests.get('https://www.billboard.com/charts/hot-100/')\n",
    "soup = BeautifulSoup(r.content, 'html.parser')\n",
    "result = soup.find_all('div', class_='o-chart-results-list-row-container')\n",
    "\n",
    "data = []\n",
    "for res in result: #Retrieving the results\n",
    "    songName = res.find('h3').text.strip()\n",
    "    artist = res.find('h3').find_next('span').text.strip()\n",
    "    data.append({'Song': songName, 'Artist': artist})\n",
    "\n",
    "    # I used stackoverflow for this \n",
    "\n",
    "df = pd.DataFrame(data) # Converting into a DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdb5769",
   "metadata": {},
   "source": [
    "# <span style=\"color:rgb(255, 0, 255)\"> Instructions of this lab goes as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f581c08",
   "metadata": {},
   "source": [
    "**Prioritize the MVP**\n",
    "\n",
    "In the previous lab, you had to scrape data about \"hot songs\". It's critical to be on track with that part, as it was part of the request from the CTO.\n",
    "\n",
    "If you couldn't finish the first lab, use this time to go back there.\n",
    "\n",
    "**Expand the project**\n",
    "\n",
    "If you're done, you can try to expand the project on your own. Here are a few suggestions:\n",
    "\n",
    "- Find other lists of hot songs on the internet and scrape them too: having a bigger pool of songs will be awesome!\n",
    "- Apply the same logic to other \"groups\" of songs: the best songs from a decade or from a country / culture / language / genre.\n",
    "- Wikipedia maintains a large collection of lists of songs: https://en.wikipedia.org/wiki/Lists_of_songs\n",
    "\n",
    "**Practice web scraping**\n",
    "\n",
    "As you've seen, scraping the internet is a skill that can get you all sorts of information. Here are some little challenges that you can try to gain more experience in the field:\n",
    "\n",
    "Retrieve an arbitrary Wikipedia page of \"Python\" and create a list of links on that page: url ='https://en.wikipedia.org/wiki/Python'\n",
    "Find the number of titles that have changed in the United States Code since its last release point: url = 'http://uscode.house.gov/download/download.shtml'\n",
    "Create a Python list with the top ten FBI's Most Wanted names: url = 'https://www.fbi.gov/wanted/topten'\n",
    "Display the 20 latest earthquakes info (date, time, latitude, longitude and region name) by the EMSC as a pandas dataframe: url = 'https://www.emsc-csem.org/Earthquake/'\n",
    "List all language names and number of related articles in the order they appear in wikipedia.org: url = 'https://www.wikipedia.org/'\n",
    "A list with the different kind of datasets available in data.gov.uk: url = 'https://data.gov.uk/'\n",
    "Display the top 10 languages by number of native speakers stored in a pandas dataframe: url = 'https://en.wikipedia.org/wiki/List_of_languages_by_number_of_native_speakers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae4b657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first try: empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "300e60b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://www.npr.org/2022/12/15/1135804266/100-best-songs-2022-page-\"\n",
    "\n",
    "# Number of pages to scrape\n",
    "num_pages = 5\n",
    "\n",
    "data_1 = []\n",
    "\n",
    "for page_num in range(1, num_pages + 1):\n",
    "    url = base_url + str(page_num)\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    song_elements = soup.find_all('h3', class_='edTag')\n",
    "\n",
    "    for element in song_elements:\n",
    "        song_info = element.text.strip()\n",
    "        song_parts = song_info.split(' \"')\n",
    "        if len(song_parts) == 2:\n",
    "            singer = song_parts[0]\n",
    "            song = song_parts[1].replace('\"', '')\n",
    "            data_1.append({'Singer': singer, 'Song': song})\n",
    "\n",
    "df_1 = pd.DataFrame(data_1)\n",
    "print(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235bf0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# second try: only the first one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d386819f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_url = \"https://www.npr.org/2022/12/15/1135804266/100-best-songs-2022-page-\"\n",
    "\n",
    "# Number of pages to scrape\n",
    "num_pages = 5\n",
    "\n",
    "data_1 = []\n",
    "\n",
    "for page_num in range(1, num_pages + 1):\n",
    "    url = base_url + str(page_num)\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    song_elements = soup.find_all('h3', attrs={\"class\":'edTag'})\n",
    "\n",
    "len(song_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5eaccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# third try: all the pages were scrapped but I have to convert it into a proper data frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7cce7715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h3 class=\"edTag\">Molly Nilsson</h3>,\n",
       " <h3 class=\"edTag\">\"Pompeii\"<em> </em></h3>,\n",
       " <h3 class=\"edTag\">Third Coast Percussion</h3>,\n",
       " <h3 class=\"edTag\">\"Derivative\"</h3>,\n",
       " <h3 class=\"edTag\">Plains</h3>,\n",
       " <h3 class=\"edTag\">\"Abilene\"</h3>,\n",
       " <h3 class=\"edTag\">Fireboy DML &amp; Asake</h3>,\n",
       " <h3 class=\"edTag\">\"Bandana\"</h3>,\n",
       " <h3 class=\"edTag\">Lizzo</h3>,\n",
       " <h3 class=\"edTag\">\"About Damn Time\"<em> </em></h3>,\n",
       " <h3 class=\"edTag\">SZA</h3>,\n",
       " <h3 class=\"edTag\">\"Shirt\"<em> </em></h3>,\n",
       " <h3 class=\"edTag\">Zach Bryan</h3>,\n",
       " <h3 class=\"edTag\">\"Something in the Orange\"</h3>,\n",
       " <h3 class=\"edTag\">Fontaines D.C.</h3>,\n",
       " <h3 class=\"edTag\">\"Jackie Down the Line\"<em> </em></h3>,\n",
       " <h3 class=\"edTag\">Harry Styles</h3>,\n",
       " <h3 class=\"edTag\">\"As It Was\"<em> </em></h3>,\n",
       " <h3 class=\"edTag\">Stromae</h3>,\n",
       " <h3 class=\"edTag\">\"L'enfer\"<em> </em></h3>,\n",
       " <h3 class=\"edTag\">Steve Lacy</h3>,\n",
       " <h3 class=\"edTag\">\"Bad Habit\"</h3>,\n",
       " <h3 class=\"edTag\">Joyce Wrice x KAYTRANADA</h3>,\n",
       " <h3 class=\"edTag\">\"Iced Tea\"<em> </em></h3>,\n",
       " <h3 class=\"edTag\">MUNA</h3>,\n",
       " <h3 class=\"edTag\">\"What I Want\"<em> </em></h3>,\n",
       " <h3 class=\"edTag\">Paramore</h3>,\n",
       " <h3 class=\"edTag\">\"This is Why\"<em> </em></h3>,\n",
       " <h3 class=\"edTag\">Gunna &amp; Future feat. Young Thug</h3>,\n",
       " <h3 class=\"edTag\">\"pushin P\"</h3>,\n",
       " <h3 class=\"edTag\">ROSALÍA</h3>,\n",
       " <h3 class=\"edTag\">\"SAOKO\"<em> </em></h3>,\n",
       " <h3 class=\"edTag\">Alex G</h3>,\n",
       " <h3 class=\"edTag\">\"Runner\"<em> </em></h3>,\n",
       " <h3 class=\"edTag\">Bad Bunny</h3>,\n",
       " <h3 class=\"edTag\">\"El Apagón\"</h3>,\n",
       " <h3 class=\"edTag\">Beyoncé</h3>,\n",
       " <h3 class=\"edTag\">\"ALIEN SUPERSTAR\"</h3>,\n",
       " <h3 class=\"edTag\">Hitkidd &amp; GloRilla</h3>,\n",
       " <h3 class=\"edTag\">\"F.N.F. (Let's Go)\"</h3>,\n",
       " <h3 class=\"edTag\">Molly Nilsson</h3>,\n",
       " <h3 class=\"edTag\">\"Pompeii\"<em> </em></h3>,\n",
       " <h3 class=\"edTag\">Third Coast Percussion</h3>,\n",
       " <h3 class=\"edTag\">\"Derivative\"</h3>,\n",
       " <h3 class=\"edTag\">Plains</h3>,\n",
       " <h3 class=\"edTag\">\"Abilene\"</h3>,\n",
       " <h3 class=\"edTag\">Fireboy DML &amp; Asake</h3>,\n",
       " <h3 class=\"edTag\">\"Bandana\"</h3>,\n",
       " <h3 class=\"edTag\">Lizzo</h3>,\n",
       " <h3 class=\"edTag\">\"About Damn Time\"<em> </em></h3>,\n",
       " <h3 class=\"edTag\">SZA</h3>,\n",
       " <h3 class=\"edTag\">\"Shirt\"<em> </em></h3>,\n",
       " <h3 class=\"edTag\">Zach Bryan</h3>,\n",
       " <h3 class=\"edTag\">\"Something in the Orange\"</h3>,\n",
       " <h3 class=\"edTag\">Fontaines D.C.</h3>,\n",
       " <h3 class=\"edTag\">\"Jackie Down the Line\"<em> </em></h3>,\n",
       " <h3 class=\"edTag\">Harry Styles</h3>,\n",
       " <h3 class=\"edTag\">\"As It Was\"<em> </em></h3>,\n",
       " <h3 class=\"edTag\">Stromae</h3>,\n",
       " <h3 class=\"edTag\">\"L'enfer\"<em> </em></h3>,\n",
       " <h3 class=\"edTag\">Steve Lacy</h3>,\n",
       " <h3 class=\"edTag\">\"Bad Habit\"</h3>,\n",
       " <h3 class=\"edTag\">Joyce Wrice x KAYTRANADA</h3>,\n",
       " <h3 class=\"edTag\">\"Iced Tea\"<em> </em></h3>,\n",
       " <h3 class=\"edTag\">MUNA</h3>,\n",
       " <h3 class=\"edTag\">\"What I Want\"<em> </em></h3>,\n",
       " <h3 class=\"edTag\">Paramore</h3>,\n",
       " <h3 class=\"edTag\">\"This is Why\"<em> </em></h3>,\n",
       " <h3 class=\"edTag\">Gunna &amp; Future feat. Young Thug</h3>,\n",
       " <h3 class=\"edTag\">\"pushin P\"</h3>,\n",
       " <h3 class=\"edTag\">ROSALÍA</h3>,\n",
       " <h3 class=\"edTag\">\"SAOKO\"<em> </em></h3>,\n",
       " <h3 class=\"edTag\">Alex G</h3>,\n",
       " <h3 class=\"edTag\">\"Runner\"<em> </em></h3>,\n",
       " <h3 class=\"edTag\">Bad Bunny</h3>,\n",
       " <h3 class=\"edTag\">\"El Apagón\"</h3>,\n",
       " <h3 class=\"edTag\">Beyoncé</h3>,\n",
       " <h3 class=\"edTag\">\"ALIEN SUPERSTAR\"</h3>,\n",
       " <h3 class=\"edTag\">Hitkidd &amp; GloRilla</h3>,\n",
       " <h3 class=\"edTag\">\"F.N.F. (Let's Go)\"</h3>,\n",
       " <h3 class=\"edTag\">Molly Nilsson</h3>,\n",
       " <h3 class=\"edTag\">\"Pompeii\"<em> </em></h3>,\n",
       " <h3 class=\"edTag\">Third Coast Percussion</h3>,\n",
       " <h3 class=\"edTag\">\"Derivative\"</h3>,\n",
       " <h3 class=\"edTag\">Plains</h3>,\n",
       " <h3 class=\"edTag\">\"Abilene\"</h3>,\n",
       " <h3 class=\"edTag\">Fireboy DML &amp; Asake</h3>,\n",
       " <h3 class=\"edTag\">\"Bandana\"</h3>,\n",
       " <h3 class=\"edTag\">Lizzo</h3>,\n",
       " <h3 class=\"edTag\">\"About Damn Time\"<em> </em></h3>,\n",
       " <h3 class=\"edTag\">SZA</h3>,\n",
       " <h3 class=\"edTag\">\"Shirt\"<em> </em></h3>,\n",
       " <h3 class=\"edTag\">Zach Bryan</h3>,\n",
       " <h3 class=\"edTag\">\"Something in the Orange\"</h3>,\n",
       " <h3 class=\"edTag\">Fontaines D.C.</h3>,\n",
       " <h3 class=\"edTag\">\"Jackie Down the Line\"<em> </em></h3>,\n",
       " <h3 class=\"edTag\">Harry Styles</h3>,\n",
       " <h3 class=\"edTag\">\"As It Was\"<em> </em></h3>,\n",
       " <h3 class=\"edTag\">Stromae</h3>,\n",
       " <h3 class=\"edTag\">\"L'enfer\"<em> </em></h3>,\n",
       " <h3 class=\"edTag\">Steve Lacy</h3>,\n",
       " <h3 class=\"edTag\">\"Bad Habit\"</h3>,\n",
       " <h3 class=\"edTag\">Joyce Wrice x KAYTRANADA</h3>,\n",
       " <h3 class=\"edTag\">\"Iced Tea\"<em> </em></h3>,\n",
       " <h3 class=\"edTag\">MUNA</h3>,\n",
       " <h3 class=\"edTag\">\"What I Want\"<em> </em></h3>,\n",
       " <h3 class=\"edTag\">Paramore</h3>,\n",
       " <h3 class=\"edTag\">\"This is Why\"<em> </em></h3>,\n",
       " <h3 class=\"edTag\">Gunna &amp; Future feat. Young Thug</h3>,\n",
       " <h3 class=\"edTag\">\"pushin P\"</h3>,\n",
       " <h3 class=\"edTag\">ROSALÍA</h3>,\n",
       " <h3 class=\"edTag\">\"SAOKO\"<em> </em></h3>,\n",
       " <h3 class=\"edTag\">Alex G</h3>,\n",
       " <h3 class=\"edTag\">\"Runner\"<em> </em></h3>,\n",
       " <h3 class=\"edTag\">Bad Bunny</h3>,\n",
       " <h3 class=\"edTag\">\"El Apagón\"</h3>,\n",
       " <h3 class=\"edTag\">Beyoncé</h3>,\n",
       " <h3 class=\"edTag\">\"ALIEN SUPERSTAR\"</h3>,\n",
       " <h3 class=\"edTag\">Hitkidd &amp; GloRilla</h3>,\n",
       " <h3 class=\"edTag\">\"F.N.F. (Let's Go)\"</h3>,\n",
       " <h3 class=\"edTag\">Molly Nilsson</h3>,\n",
       " <h3 class=\"edTag\">\"Pompeii\"<em> </em></h3>,\n",
       " <h3 class=\"edTag\">Third Coast Percussion</h3>,\n",
       " <h3 class=\"edTag\">\"Derivative\"</h3>,\n",
       " <h3 class=\"edTag\">Plains</h3>,\n",
       " <h3 class=\"edTag\">\"Abilene\"</h3>,\n",
       " <h3 class=\"edTag\">Fireboy DML &amp; Asake</h3>,\n",
       " <h3 class=\"edTag\">\"Bandana\"</h3>,\n",
       " <h3 class=\"edTag\">Lizzo</h3>,\n",
       " <h3 class=\"edTag\">\"About Damn Time\"<em> </em></h3>,\n",
       " <h3 class=\"edTag\">SZA</h3>,\n",
       " <h3 class=\"edTag\">\"Shirt\"<em> </em></h3>,\n",
       " <h3 class=\"edTag\">Zach Bryan</h3>,\n",
       " <h3 class=\"edTag\">\"Something in the Orange\"</h3>,\n",
       " <h3 class=\"edTag\">Fontaines D.C.</h3>,\n",
       " <h3 class=\"edTag\">\"Jackie Down the Line\"<em> </em></h3>,\n",
       " <h3 class=\"edTag\">Harry Styles</h3>,\n",
       " <h3 class=\"edTag\">\"As It Was\"<em> </em></h3>,\n",
       " <h3 class=\"edTag\">Stromae</h3>,\n",
       " <h3 class=\"edTag\">\"L'enfer\"<em> </em></h3>,\n",
       " <h3 class=\"edTag\">Steve Lacy</h3>,\n",
       " <h3 class=\"edTag\">\"Bad Habit\"</h3>,\n",
       " <h3 class=\"edTag\">Joyce Wrice x KAYTRANADA</h3>,\n",
       " <h3 class=\"edTag\">\"Iced Tea\"<em> </em></h3>,\n",
       " <h3 class=\"edTag\">MUNA</h3>,\n",
       " <h3 class=\"edTag\">\"What I Want\"<em> </em></h3>,\n",
       " <h3 class=\"edTag\">Paramore</h3>,\n",
       " <h3 class=\"edTag\">\"This is Why\"<em> </em></h3>,\n",
       " <h3 class=\"edTag\">Gunna &amp; Future feat. Young Thug</h3>,\n",
       " <h3 class=\"edTag\">\"pushin P\"</h3>,\n",
       " <h3 class=\"edTag\">ROSALÍA</h3>,\n",
       " <h3 class=\"edTag\">\"SAOKO\"<em> </em></h3>,\n",
       " <h3 class=\"edTag\">Alex G</h3>,\n",
       " <h3 class=\"edTag\">\"Runner\"<em> </em></h3>,\n",
       " <h3 class=\"edTag\">Bad Bunny</h3>,\n",
       " <h3 class=\"edTag\">\"El Apagón\"</h3>,\n",
       " <h3 class=\"edTag\">Beyoncé</h3>,\n",
       " <h3 class=\"edTag\">\"ALIEN SUPERSTAR\"</h3>,\n",
       " <h3 class=\"edTag\">Hitkidd &amp; GloRilla</h3>,\n",
       " <h3 class=\"edTag\">\"F.N.F. (Let's Go)\"</h3>,\n",
       " <h3 class=\"edTag\">Molly Nilsson</h3>,\n",
       " <h3 class=\"edTag\">\"Pompeii\"<em> </em></h3>,\n",
       " <h3 class=\"edTag\">Third Coast Percussion</h3>,\n",
       " <h3 class=\"edTag\">\"Derivative\"</h3>,\n",
       " <h3 class=\"edTag\">Plains</h3>,\n",
       " <h3 class=\"edTag\">\"Abilene\"</h3>,\n",
       " <h3 class=\"edTag\">Fireboy DML &amp; Asake</h3>,\n",
       " <h3 class=\"edTag\">\"Bandana\"</h3>,\n",
       " <h3 class=\"edTag\">Lizzo</h3>,\n",
       " <h3 class=\"edTag\">\"About Damn Time\"<em> </em></h3>,\n",
       " <h3 class=\"edTag\">SZA</h3>,\n",
       " <h3 class=\"edTag\">\"Shirt\"<em> </em></h3>,\n",
       " <h3 class=\"edTag\">Zach Bryan</h3>,\n",
       " <h3 class=\"edTag\">\"Something in the Orange\"</h3>,\n",
       " <h3 class=\"edTag\">Fontaines D.C.</h3>,\n",
       " <h3 class=\"edTag\">\"Jackie Down the Line\"<em> </em></h3>,\n",
       " <h3 class=\"edTag\">Harry Styles</h3>,\n",
       " <h3 class=\"edTag\">\"As It Was\"<em> </em></h3>,\n",
       " <h3 class=\"edTag\">Stromae</h3>,\n",
       " <h3 class=\"edTag\">\"L'enfer\"<em> </em></h3>,\n",
       " <h3 class=\"edTag\">Steve Lacy</h3>,\n",
       " <h3 class=\"edTag\">\"Bad Habit\"</h3>,\n",
       " <h3 class=\"edTag\">Joyce Wrice x KAYTRANADA</h3>,\n",
       " <h3 class=\"edTag\">\"Iced Tea\"<em> </em></h3>,\n",
       " <h3 class=\"edTag\">MUNA</h3>,\n",
       " <h3 class=\"edTag\">\"What I Want\"<em> </em></h3>,\n",
       " <h3 class=\"edTag\">Paramore</h3>,\n",
       " <h3 class=\"edTag\">\"This is Why\"<em> </em></h3>,\n",
       " <h3 class=\"edTag\">Gunna &amp; Future feat. Young Thug</h3>,\n",
       " <h3 class=\"edTag\">\"pushin P\"</h3>,\n",
       " <h3 class=\"edTag\">ROSALÍA</h3>,\n",
       " <h3 class=\"edTag\">\"SAOKO\"<em> </em></h3>,\n",
       " <h3 class=\"edTag\">Alex G</h3>,\n",
       " <h3 class=\"edTag\">\"Runner\"<em> </em></h3>,\n",
       " <h3 class=\"edTag\">Bad Bunny</h3>,\n",
       " <h3 class=\"edTag\">\"El Apagón\"</h3>,\n",
       " <h3 class=\"edTag\">Beyoncé</h3>,\n",
       " <h3 class=\"edTag\">\"ALIEN SUPERSTAR\"</h3>,\n",
       " <h3 class=\"edTag\">Hitkidd &amp; GloRilla</h3>,\n",
       " <h3 class=\"edTag\">\"F.N.F. (Let's Go)\"</h3>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "base_url = \"https://www.npr.org/2022/12/15/1135804266/100-best-songs-2022-page-\"\n",
    "\n",
    "# Number of pages to scrape\n",
    "num_pages = 5\n",
    "\n",
    "data_1 = []\n",
    "\n",
    "for page_num in range(1, num_pages + 1):\n",
    "    url = base_url + str(page_num)\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    song_elements = soup.find_all('h3', attrs={\"class\": 'edTag'})\n",
    "    \n",
    "    data_1.extend(song_elements)\n",
    "data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "980de38d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song</th>\n",
       "      <th>Artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pompeii</td>\n",
       "      <td>Molly Nilsson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Derivative</td>\n",
       "      <td>Third Coast Percussion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abilene</td>\n",
       "      <td>Plains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bandana</td>\n",
       "      <td>Fireboy DML &amp; Asake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>About Damn Time</td>\n",
       "      <td>Lizzo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>SAOKO</td>\n",
       "      <td>ROSALÍA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Runner</td>\n",
       "      <td>Alex G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>El Apagón</td>\n",
       "      <td>Bad Bunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ALIEN SUPERSTAR</td>\n",
       "      <td>Beyoncé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>F.N.F. (Let's Go)</td>\n",
       "      <td>Hitkidd &amp; GloRilla</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Song                  Artist\n",
       "0             Pompeii           Molly Nilsson\n",
       "1          Derivative  Third Coast Percussion\n",
       "2             Abilene                  Plains\n",
       "3             Bandana     Fireboy DML & Asake\n",
       "4     About Damn Time                   Lizzo\n",
       "..                ...                     ...\n",
       "95              SAOKO                 ROSALÍA\n",
       "96             Runner                  Alex G\n",
       "97          El Apagón               Bad Bunny\n",
       "98    ALIEN SUPERSTAR                 Beyoncé\n",
       "99  F.N.F. (Let's Go)      Hitkidd & GloRilla\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So now we need to extract singer and song from data_1 and create a DataFrame\n",
    "\n",
    "singers = []\n",
    "songs = []\n",
    "\n",
    "for i in range(0, len(data_1), 2):\n",
    "    singer = data_1[i].text.strip()\n",
    "    song = data_1[i+1].text.strip('\"').strip()\n",
    "    if song.endswith('\"'):\n",
    "        song = song[:-1].strip()\n",
    "    songs.append(song)\n",
    "    singers.append(singer)\n",
    "\n",
    "df_1 = pd.DataFrame({'Song': songs, 'Artist': singers})\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "49e2704a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song</th>\n",
       "      <th>Artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Last Night</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flowers</td>\n",
       "      <td>Miley Cyrus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fast Car</td>\n",
       "      <td>Luke Combs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Calm Down</td>\n",
       "      <td>Rema &amp; Selena Gomez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>All My Life</td>\n",
       "      <td>Lil Durk Featuring J. Cole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>SAOKO</td>\n",
       "      <td>ROSALÍA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Runner</td>\n",
       "      <td>Alex G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>El Apagón</td>\n",
       "      <td>Bad Bunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>ALIEN SUPERSTAR</td>\n",
       "      <td>Beyoncé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>F.N.F. (Let's Go)</td>\n",
       "      <td>Hitkidd &amp; GloRilla</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Song                      Artist\n",
       "0           Last Night               Morgan Wallen\n",
       "1              Flowers                 Miley Cyrus\n",
       "2             Fast Car                  Luke Combs\n",
       "3            Calm Down         Rema & Selena Gomez\n",
       "4          All My Life  Lil Durk Featuring J. Cole\n",
       "..                 ...                         ...\n",
       "195              SAOKO                     ROSALÍA\n",
       "196             Runner                      Alex G\n",
       "197          El Apagón                   Bad Bunny\n",
       "198    ALIEN SUPERSTAR                     Beyoncé\n",
       "199  F.N.F. (Let's Go)          Hitkidd & GloRilla\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_list = pd.concat([df, df_1], ignore_index=True)\n",
    "final_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
